import time
import json
import re
import requests
import streamlit as st
from datetime import datetime
import pytz
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from supabase import create_client, Client

# ==================================================
# 1. è¨­å®šã‚¨ãƒªã‚¢
# ==================================================

def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]: return True
    
    st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³")
    ADMIN_PASS = st.secrets.get("ADMIN_PASSWORD", "admin123")
    val = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if st.button("Login"):
        if val == ADMIN_PASS:
            st.session_state["password_correct"] = True
            st.rerun()
        else: st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    return False

if not check_password(): st.stop()

# Secrets
KEIBA_ID = st.secrets.get("KEIBA_ID", "")
KEIBA_PASS = st.secrets.get("KEIBA_PASS", "")
DIFY_API_KEY = st.secrets.get("DIFY_API_KEY", "")
SUPABASE_URL = st.secrets.get("SUPABASE_URL", "")
SUPABASE_ANON_KEY = st.secrets.get("SUPABASE_ANON_KEY", "")

PLACE_NAMES = {"10": "å¤§äº•", "11": "å·å´", "12": "èˆ¹æ©‹", "13": "æµ¦å’Œ"}

# ==================================================
# 2. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==================================================

@st.cache_resource
def get_supabase_client() -> Client | None:
    if not SUPABASE_URL or not SUPABASE_ANON_KEY: return None
    return create_client(SUPABASE_URL, SUPABASE_ANON_KEY)

def save_history(year, place_code, place_name, month, day, race_num_str, race_id, ai_answer):
    supabase = get_supabase_client()
    if not supabase: return
    data = {
        "year": str(year), "place_code": str(place_code), "place_name": place_name,
        "day": str(day), "month": str(month), "race_num": race_num_str,
        "race_id": race_id, "output_text": ai_answer
    }
    try:
        supabase.table("history").insert(data).execute()
    except Exception as e:
        st.error(f"Supabase error: {e}")

def get_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1280,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(options=options)

def login_keibabook(driver):
    if not KEIBA_ID or not KEIBA_PASS:
        st.warning("âš ï¸ ID/PASSæœªè¨­å®š")
        return False
    try:
        driver.get("https://s.keibabook.co.jp/login/login")
        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.NAME, "login_id"))).send_keys(KEIBA_ID)
        driver.find_element(By.CSS_SELECTOR, "input[type='password']").send_keys(KEIBA_PASS)
        driver.find_element(By.CSS_SELECTOR, "input[type='submit']").click()
        time.sleep(1)
        return True
    except: return False

def fetch_race_ids(driver, year, month, day, p_code):
    url = f"https://s.keibabook.co.jp/chihou/nittei/{year}{month}{day}10"
    st.info(f"ğŸ“… æ—¥ç¨‹å–å¾—: {url}")
    driver.get(url)
    time.sleep(1)
    soup = BeautifulSoup(driver.page_source, "html.parser")
    ids = []
    seen = set()
    for a in soup.find_all("a", href=True):
        m = re.search(r'(\d{16})', a['href'])
        if m:
            rid = m.group(1)
            if rid[6:8] == p_code and rid not in seen:
                ids.append(rid)
                seen.add(rid)
    return sorted(ids)

def get_race_meta(html):
    soup = BeautifulSoup(html, "html.parser")
    rt = soup.find("div", class_="racetitle")
    if not rt: return {}
    rm = rt.find("div", class_="racemei")
    rname = rm.find_all("p")[1].get_text(strip=True) if rm and len(rm.find_all("p")) > 1 else ""
    rs = rt.find("div", class_="racetitle_sub")
    cond = rs.find_all("p")[1].get_text(" ", strip=True) if rs and len(rs.find_all("p")) > 1 else ""
    return {"name": rname, "cond": cond}

# ==================================================
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ (HTMLè§£æ)
# ==================================================

def parse_syutuba_page(html):
    """
    ã€å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸ã€‘è§£æ
    æä¾›ã•ã‚ŒãŸHTMLã«åŸºã¥ãã€<table class="syutuba_sp"> ã‚’è§£æã™ã‚‹
    """
    soup = BeautifulSoup(html, "html.parser")
    data = {}

    # æä¾›ã•ã‚ŒãŸHTMLã«ã‚ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¯ãƒ©ã‚¹
    table = soup.find("table", class_="syutuba_sp")
    
    if not table:
        return {}

    # tbodyå†…ã®è¡Œã‚’å–å¾—
    rows = table.find("tbody").find_all("tr")
    
    for row in rows:
        # 1. é¦¬ç•ªã®å–å¾— (æœ€åˆã®td)
        tds = row.find_all("td")
        if not tds: continue
        
        # class="waku1" ç­‰ãŒã¤ã„ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ãŒã€ä½ç½®ã§å–å¾—ãŒç¢ºå®Ÿ
        umaban = tds[0].get_text(strip=True)
        if not umaban.isdigit(): continue # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œãªã©ã®é™¤å¤–

        # 2. é¦¬åã¨é¨æ‰‹ã®å–å¾— (class="left" ã®tdå†…ã«ã‚ã‚‹)
        info_td = row.find("td", class_="left")
        if not info_td: continue

        # é¦¬å <p class="kbamei">
        kbamei_p = info_td.find("p", class_="kbamei")
        horse_name = kbamei_p.get_text(strip=True) if kbamei_p else "ä¸æ˜"

        # é¨æ‰‹ <p class="kisyu">
        kisyu_p = info_td.find("p", class_="kisyu")
        jockey = "ä¸æ˜"
        is_change = False
        
        if kisyu_p:
            # <a>ã‚¿ã‚°ã®ä¸­ã«é¨æ‰‹åãŒã‚ã‚‹
            a_tag = kisyu_p.find("a")
            if a_tag:
                jockey = a_tag.get_text(strip=True)
                # ä¹—ã‚Šæ›¿ã‚ã‚Šåˆ¤å®š: <a>ã®ä¸­ã« <strong> ã¾ãŸã¯ <b> ãŒã‚ã‚‹ã‹
                if a_tag.find(["strong", "b"]):
                    is_change = True
            else:
                # ãƒªãƒ³ã‚¯ãŒãªã„å ´åˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                # "ç‰¡2 æ¡‘æ‘çœŸ 55" ã®ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€å˜ç´”å–å¾—ã¯å±é™ºã ãŒã¨ã‚Šã‚ãˆãšå–å¾—
                jockey = kisyu_p.get_text(strip=True)
            
            # è¦ªã‚¿ã‚°ãƒ¬ãƒ™ãƒ«ã§ã®å¼·èª¿ãƒã‚§ãƒƒã‚¯
            if kisyu_p.find(["strong", "b"]):
                is_change = True

        data[umaban] = {
            "horse": horse_name,
            "jockey": jockey,
            "is_change": is_change
        }
            
    return data

def parse_danwa_page(html):
    """
    ã€è«‡è©±ãƒšãƒ¼ã‚¸ã€‘è§£æ
    èª¿æ•™å¸«åã¯ã“ã®ãƒšãƒ¼ã‚¸ã®ã‚³ãƒ¡ãƒ³ãƒˆæœ¬æ–‡ã‹ã‚‰æŠ½å‡ºã™ã‚‹
    """
    soup = BeautifulSoup(html, "html.parser")
    data = {}
    table = soup.find("table", class_="danwa")
    if table and table.tbody:
        current_uma = None
        for row in table.tbody.find_all("tr"):
            u_td = row.find("td", class_="umaban")
            if u_td:
                current_uma = u_td.get_text(strip=True)
                continue
            txt_td = row.find("td", class_="danwa")
            if txt_td and current_uma:
                text = txt_td.get_text(strip=True)
                # ã‚³ãƒ¡ãƒ³ãƒˆå†…ã®ã€Œã€‡ã€‡å¸«ã€ã‚’æ­£è¦è¡¨ç¾ã§æ¢ã™
                trainer = "ä¸æ˜"
                m = re.search(r'(\S+å¸«)', text)
                if m: trainer = m.group(1)
                
                data[current_uma] = {"comment": text, "trainer": trainer}
                current_uma = None
    return data

def parse_cyokyo_page(html):
    """
    ã€èª¿æ•™ãƒšãƒ¼ã‚¸ã€‘è§£æ
    """
    soup = BeautifulSoup(html, "html.parser")
    data = {}
    tables = soup.find_all("table", class_="cyokyo")
    for tbl in tables:
        tbody = tbl.find("tbody")
        if not tbody: continue
        rows = tbody.find_all("tr", recursive=False)
        if len(rows) < 2: continue
        
        r1 = rows[0]
        u_td = r1.find("td", class_="umaban")
        if not u_td: continue
        umaban = u_td.get_text(strip=True)
        
        tanpyo_td = r1.find("td", class_="tanpyo")
        tanpyo = tanpyo_td.get_text(strip=True) if tanpyo_td else ""
        
        r2 = rows[1]
        detail = r2.get_text(" ", strip=True)
        
        data[umaban] = {"tanpyo": tanpyo, "time": detail}
        
    return data

# ==================================================
# 4. Dify API
# ==================================================

def stream_dify(text):
    if not DIFY_API_KEY:
        yield "âš ï¸ API Keyæœªè¨­å®š"
        return
    headers = {"Authorization": f"Bearer {DIFY_API_KEY}", "Content-Type": "application/json"}
    payload = {"inputs": {"text": text}, "response_mode": "streaming", "user": "keiba-bot"}
    
    try:
        res = requests.post("https://api.dify.ai/v1/workflows/run", headers=headers, json=payload, stream=True, timeout=120)
        for line in res.iter_lines():
            if line:
                d = line.decode('utf-8')
                if d.startswith("data:"):
                    try:
                        j = json.loads(d.replace("data: ", ""))
                        if "answer" in j: yield j["answer"]
                    except: pass
    except Exception as e:
        yield f"Error: {e}"

# ==================================================
# 5. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
# ==================================================

st.title("ğŸ‡ ç«¶é¦¬ãƒ–ãƒƒã‚¯å®Œå…¨å–å¾—Bot")
jst = pytz.timezone('Asia/Tokyo')
now = datetime.now(jst)

with st.container():
    c1, c2 = st.columns(2)
    with c1: target_date = st.date_input("æ—¥ä»˜", now)
    with c2: PLACE_CODE = st.selectbox("å ´æ‰€", ["10","11","12","13"], format_func=lambda x: f"{x}:{PLACE_NAMES[x]}")
    
    all_races = st.checkbox("å…¨ãƒ¬ãƒ¼ã‚¹", value=True)
    target_races = []
    if not all_races:
        cols = st.columns(6)
        for i in range(1, 13):
            with cols[(i-1)//2]:
                if st.checkbox(f"{i}R", key=f"r{i}"): target_races.append(i)
    else: target_races = list(range(1,13))

if st.button("ğŸš€ åˆ†æé–‹å§‹", type="primary"):
    ymd = target_date.strftime("%Y%m%d")
    pname = PLACE_NAMES[PLACE_CODE]
    driver = get_driver()
    
    try:
        st.info("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³ä¸­...")
        if not login_keibabook(driver):
            st.stop()
            
        st.info("ğŸ“¡ ãƒ¬ãƒ¼ã‚¹IDå–å¾—ä¸­...")
        rids = fetch_race_ids(driver, target_date.strftime("%Y"), target_date.strftime("%m"), target_date.strftime("%d"), PLACE_CODE)
        
        if not rids:
            st.error("ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            for rid in rids:
                rnum = int(rid[10:12])
                if target_races and rnum not in target_races: continue
                
                st.markdown(f"### {pname} {rnum}R")
                status = st.empty()
                res_area = st.empty()
                
                try:
                    status.info("ğŸ“š ãƒ‡ãƒ¼ã‚¿åé›†ä¸­ (å‡ºé¦¬è¡¨/è«‡è©±/èª¿æ•™)...")
                    
                    # 1. å‡ºé¦¬è¡¨ (é¨æ‰‹ãƒ»ä¹—ã‚Šæ›¿ã‚ã‚Šãƒ»é¦¬å)
                    driver.get(f"https://s.keibabook.co.jp/chihou/syutuba/{rid}")
                    syutuba_data = parse_syutuba_page(driver.page_source)
                    
                    # 2. è«‡è©± (ã‚³ãƒ¡ãƒ³ãƒˆãƒ»èª¿æ•™å¸«)
                    driver.get(f"https://s.keibabook.co.jp/chihou/danwa/1/{rid}")
                    danwa_html = driver.page_source
                    meta = get_race_meta(danwa_html)
                    danwa_data = parse_danwa_page(danwa_html)
                    
                    # 3. èª¿æ•™ (ã‚¿ã‚¤ãƒ )
                    driver.get(f"https://s.keibabook.co.jp/chihou/cyokyo/1/{rid}")
                    cyokyo_data = parse_cyokyo_page(driver.page_source)
                    
                    # 4. çµåˆ
                    all_keys = set(syutuba_data.keys()) | set(danwa_data.keys()) | set(cyokyo_data.keys())
                    sorted_umas = sorted(list(all_keys), key=lambda x: int(x) if x.isdigit() else 999)
                    
                    lines = []
                    for u in sorted_umas:
                        s = syutuba_data.get(u, {})
                        d = danwa_data.get(u, {})
                        c = cyokyo_data.get(u, {})
                        
                        horse = s.get("horse", "ä¸æ˜")
                        jock = s.get("jockey", "ä¸æ˜")
                        change = "ã€âš ï¸ä¹—ã‚Šæ›¿ã‚ã‚Šã€‘" if s.get("is_change") else ""
                        
                        comment = d.get("comment", "ãªã—")
                        trainer = d.get("trainer", "ä¸æ˜") 
                        
                        cyokyo = f"{c.get('tanpyo','')} {c.get('time','')}"
                        
                        lines.append(
                            f"â–¼[é¦¬ç•ª{u}] {horse}\n"
                            f"  é¨æ‰‹: {jock} {change}\n"
                            f"  èª¿æ•™å¸«: {trainer}\n"
                            f"  å©èˆã®è©±: {comment}\n"
                            f"  èª¿æ•™: {cyokyo}"
                        )
                    
                    if not lines:
                        status.warning("ãƒ‡ãƒ¼ã‚¿ãªã—")
                        continue
                        
                    prompt = (
                        f"ãƒ¬ãƒ¼ã‚¹: {meta.get('name','')}\næ¡ä»¶: {meta.get('cond','')}\n\n"
                        "ãƒ¬ãƒ¼ã‚¹å…¨å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿(é¨æ‰‹,èª¿æ•™å¸«,å©èˆã®è©±,èª¿æ•™)ã€‚\n"
                        "èª¿æ•™å¸«åã¯ã€Œå©èˆã®è©±ã€ã«å«ã¾ã‚Œã¦ã„ã‚‹ã€‚\n"
                        + "\n".join(lines)
                    )
                    
                    status.info("ğŸ¤– AIåˆ†æä¸­...")
                    ans = ""
                    for chunk in stream_dify(prompt):
                        ans += chunk
                        res_area.markdown(ans + "â–Œ")
                    res_area.markdown(ans)
                    
                    save_history(target_date.year, PLACE_CODE, pname, target_date.month, target_date.day, f"{rnum:02}", rid, ans)
                    status.success("å®Œäº†")
                    
                except Exception as e:
                    status.error(f"Error: {e}")
                
                st.divider()
                
    finally:
        driver.quit()
