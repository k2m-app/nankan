# keiba_bot.py
import time
import json
import re
import requests
import streamlit as st

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options

from bs4 import BeautifulSoup
from supabase import create_client, Client

from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ==================================================
# ã€è¨­å®šã€‘Secretsèª­ã¿è¾¼ã¿
# ==================================================
KEIBA_ID = st.secrets.get("KEIBA_ID", "")
KEIBA_PASS = st.secrets.get("KEIBA_PASS", "")
DIFY_API_KEY = st.secrets.get("DIFY_API_KEY", "")

# self-host ã®å ´åˆã¯ã“ã“ã‚’è‡ªåˆ†ã®Difyãƒ‰ãƒ¡ã‚¤ãƒ³ã«ï¼ˆä¾‹: https://dify.example.comï¼‰
DIFY_BASE_URL = st.secrets.get("DIFY_BASE_URL", "https://api.dify.ai")

SUPABASE_URL = st.secrets.get("SUPABASE_URL", "")
SUPABASE_ANON_KEY = st.secrets.get("SUPABASE_ANON_KEY", "")

# ==================================================
# å†…éƒ¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼šUIå‡ºåŠ›ã®ON/OFFã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
# ==================================================
def _ui_info(ui: bool, msg: str):
    if ui:
        st.info(msg)

def _ui_success(ui: bool, msg: str):
    if ui:
        st.success(msg)

def _ui_warning(ui: bool, msg: str):
    if ui:
        st.warning(msg)

def _ui_error(ui: bool, msg: str):
    if ui:
        st.error(msg)

def _ui_caption(ui: bool, msg: str):
    if ui:
        st.caption(msg)

def _ui_markdown(ui: bool, msg: str):
    if ui:
        st.markdown(msg)

def _ui_divider(ui: bool):
    if ui:
        st.divider()

# ==================================================
# requests session + retry
# ==================================================
def _build_requests_session(total: int = 3, backoff: float = 0.6) -> requests.Session:
    sess = requests.Session()
    retry = Retry(
        total=total,
        connect=total,
        read=total,
        backoff_factor=backoff,
        status_forcelist=(429, 500, 502, 503, 504),
        allowed_methods=("GET", "POST"),
        raise_on_status=False,
    )
    adapter = HTTPAdapter(max_retries=retry)
    sess.mount("https://", adapter)
    sess.mount("http://", adapter)
    return sess

# ä½¿ã„å›ã—ï¼ˆDifyï¼‰
@st.cache_resource
def get_http_session() -> requests.Session:
    return _build_requests_session(total=3, backoff=0.6)

# ==================================================
# Supabase
# ==================================================
@st.cache_resource
def get_supabase_client() -> Client | None:
    if not SUPABASE_URL or not SUPABASE_ANON_KEY:
        return None
    try:
        return create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
    except Exception as e:
        print("Supabase client error:", e)
        return None

def save_history(year, place_code, place_name, month, day, race_num_str, race_id, ai_answer):
    supabase = get_supabase_client()
    if not supabase:
        return
    data = {
        "year": str(year),
        "place_code": str(place_code),
        "place_name": place_name,
        "month": str(month).zfill(2),
        "day": str(day).zfill(2),
        "race_num": str(race_num_str),
        "race_id": str(race_id),
        "output_text": ai_answer,
    }
    try:
        supabase.table("history").insert(data).execute()
    except Exception as e:
        print("Supabase insert error:", e)

# ==================================================
# Selenium Driverï¼ˆç«¶é¦¬ãƒ–ãƒƒã‚¯ç”¨ï¼‰
# ==================================================
def build_driver() -> webdriver.Chrome:
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1400,2200")
    return webdriver.Chrome(options=options)

def login_keibabook(driver: webdriver.Chrome, wait: WebDriverWait):
    driver.get("https://s.keibabook.co.jp/login/login")
    wait.until(EC.visibility_of_element_located((By.NAME, "login_id"))).send_keys(KEIBA_ID)
    driver.find_element(By.CSS_SELECTOR, "input[type='password']").send_keys(KEIBA_PASS)
    driver.find_element(By.CSS_SELECTOR, "input[type='submit']").click()
    time.sleep(1)

# ==================================================
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼šæ—¥ç¨‹â†’ãƒ¬ãƒ¼ã‚¹IDä¸€è¦§ï¼ˆç«¶é¦¬ãƒ–ãƒƒã‚¯ï¼‰
# ==================================================
def fetch_race_ids_from_schedule(driver, year, month, day, target_place_code, ui: bool = False):
    """
    æ—¥ç¨‹ãƒšãƒ¼ã‚¸ã‹ã‚‰ã€ŒæŒ‡å®šç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ã€ã®ãƒ¬ãƒ¼ã‚¹ID(16æ¡)ã‚’æ‹¾ã†ï¼ˆç«¶é¦¬ãƒ–ãƒƒã‚¯ï¼‰
    """
    date_str = f"{year}{month}{day}"
    url = f"https://s.keibabook.co.jp/chihou/nittei/{date_str}10"

    _ui_info(ui, f"ğŸ“… æ—¥ç¨‹ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—ä¸­... ({url})")
    driver.get(url)

    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "a")))
    except:
        pass

    soup = BeautifulSoup(driver.page_source, "html.parser")
    race_ids = []
    seen = set()

    for a in soup.find_all("a", href=True):
        href = a["href"]
        m = re.search(r"(\d{16})", href)
        if not m:
            continue
        rid = m.group(1)

        # rid[6:8] ãŒç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ï¼ˆç«¶é¦¬ãƒ–ãƒƒã‚¯å´ï¼‰
        if rid[6:8] == target_place_code:
            if rid not in seen:
                race_ids.append(rid)
                seen.add(rid)

    race_ids.sort()
    if not race_ids:
        _ui_warning(ui, f"âš ï¸ æŒ‡å®šã—ãŸç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰({target_place_code})ã®ãƒ¬ãƒ¼ã‚¹IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        _ui_success(ui, f"âœ… {len(race_ids)} ä»¶ã®ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
    return race_ids

# ==================================================
# ç«¶é¦¬ãƒ–ãƒƒã‚¯ï¼šãƒ¬ãƒ¼ã‚¹æƒ…å ±/è«‡è©±/èª¿æ•™
# ==================================================
def parse_race_info(html: str):
    soup = BeautifulSoup(html, "html.parser")
    racetitle = soup.find("div", class_="racetitle")
    if not racetitle:
        return {}

    racemei = racetitle.find("div", class_="racemei")
    p_tags = racemei.find_all("p") if racemei else []
    race_name = ""
    if len(p_tags) >= 2:
        race_name = p_tags[1].get_text(strip=True)
    elif len(p_tags) == 1:
        race_name = p_tags[0].get_text(strip=True)

    sub = racetitle.find("div", class_="racetitle_sub")
    sub_p = sub.find_all("p") if sub else []
    cond = sub_p[1].get_text(" ", strip=True) if len(sub_p) >= 2 else ""

    return {"race_name": race_name, "cond": cond}

def parse_danwa_comments(html: str):
    soup = BeautifulSoup(html, "html.parser")
    danwa_dict = {}
    table = soup.find("table", class_="danwa")

    if table and table.tbody:
        current_uma = None
        for row in table.tbody.find_all("tr"):
            uma_td = row.find("td", class_="umaban")
            if uma_td:
                current_uma = uma_td.get_text(strip=True)
                continue

            txt_td = row.find("td", class_="danwa")
            if txt_td and current_uma:
                danwa_dict[current_uma] = txt_td.get_text(strip=True)
                current_uma = None

    return danwa_dict

def parse_cyokyo(html: str):
    soup = BeautifulSoup(html, "html.parser")
    cyokyo_dict = {}
    tables = soup.find_all("table", class_="cyokyo")
    for tbl in tables:
        tbody = tbl.find("tbody")
        if not tbody:
            continue
        rows = tbody.find_all("tr", recursive=False)
        if not rows:
            continue

        h_row = rows[0]
        uma_td = h_row.find("td", class_="umaban")
        name_td = h_row.find("td", class_="kbamei")
        if not uma_td or not name_td:
            continue

        umaban = uma_td.get_text(strip=True)
        bamei = name_td.get_text(" ", strip=True)

        tanpyo_elem = h_row.find("td", class_="tanpyo")
        tanpyo = tanpyo_elem.get_text(strip=True) if tanpyo_elem else ""
        detail = rows[1].get_text(" ", strip=True) if len(rows) > 1 else ""

        cyokyo_dict[umaban] = f"ã€é¦¬åã€‘{bamei} ã€çŸ­è©•ã€‘{tanpyo} ã€è©³ç´°ã€‘{detail}"

    return cyokyo_dict

# ==================================================
# åœ°æ–¹ç«¶é¦¬å…¬å¼ï¼ˆkeiba.go.jpï¼‰ï¼šDOMã§å‡ºé¦¬è¡¨ã‚’å …ç‰¢ã«ãƒ‘ãƒ¼ã‚¹
# ==================================================
_KEIBAGO_UA = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                  "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
}

def _norm_name(s: str) -> str:
    s = (s or "").strip().replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s)
    s = s.replace("â–²", "").replace("â–³", "").replace("â˜†", "").replace("â—‡", "")
    return s.strip()

_WEIGHT_RE = re.compile(r"^[â˜†â–²â–³â—‡]?\s*\d{1,2}\.\d$")  # 55.0 / â˜† 53.0 ç­‰
_PREV_JOCKEY_RE = re.compile(r"\d+äºº\s+([â˜†â–²â–³â—‡]?\s*\S+)\s+\d{1,2}\.\d")  # "5äºº â–²é«˜æ©‹å„ª 52.0" ç­‰

def _extract_jockey_from_cell(td) -> str:
    lines = [x.strip() for x in td.get_text("\n", strip=True).split("\n") if x.strip()]
    lines2 = [ln for ln in lines if not _WEIGHT_RE.match(ln)]
    if lines2:
        return lines2[0].replace(" ", "")
    return "ä¸æ˜"

def fetch_keibago_debatable_small(year: str, month: str, day: str, race_no: int, baba_code: str):
    """
    keiba.go.jp DebaTableSmall ã‚’å …ç‰¢ã«èª­ã‚€ç‰ˆï¼ˆrowspan/åˆ—ã‚ºãƒ¬è€æ€§ã‚ã‚Šï¼‰
    """
    date_str = f"{year}/{str(month).zfill(2)}/{str(day).zfill(2)}"
    url = (
        "https://www.keiba.go.jp/KeibaWeb/TodayRaceInfo/DebaTableSmall"
        f"?k_raceDate={requests.utils.quote(date_str)}&k_raceNo={race_no}&k_babaCode={baba_code}"
    )

    sess = _build_requests_session(total=3, backoff=0.6)
    r = sess.get(url, headers=_KEIBAGO_UA, timeout=25)
    r.raise_for_status()
    r.encoding = r.apparent_encoding or "utf-8"
    soup = BeautifulSoup(r.text, "html.parser")

    header = ""
    top_bs = soup.select_one("table.bs")
    if top_bs:
        header = top_bs.get_text(" ", strip=True)

    main_table = soup.select_one("td.dbtbl table.bs[border='1']")
    if not main_table:
        main_table = soup.select_one("table.bs[border='1']")

    horses = {}
    last_waku = ""

    if not main_table:
        return header, horses, url

    for tr in main_table.find_all("tr"):
        if not tr.select_one("font.bamei"):
            continue

        tds = tr.find_all("td", recursive=False)
        if len(tds) < 8:
            continue

        first_txt = tds[0].get_text(strip=True)
        waku_present = first_txt.isdigit() and len(tds) >= 9
        if waku_present:
            second_txt = tds[1].get_text(strip=True)
            if not second_txt.isdigit():
                waku_present = False

        if waku_present:
            waku = tds[0].get_text(strip=True)
            umaban = tds[1].get_text(strip=True)
            horse_td = tds[2]
            trainer_td = tds[3]
            jockey_td = tds[4]
            zenso_td = tds[8] if len(tds) > 8 else None
            last_waku = waku
        else:
            waku = last_waku or ""
            umaban = tds[0].get_text(strip=True)
            horse_td = tds[1]
            trainer_td = tds[2]
            jockey_td = tds[3]
            zenso_td = tds[7] if len(tds) > 7 else None

        if not umaban.isdigit():
            continue

        bamei_tag = horse_td.select_one("font.bamei b")
        horse = bamei_tag.get_text(strip=True) if bamei_tag else horse_td.get_text(" ", strip=True)

        trainer_raw = trainer_td.get_text(" ", strip=True)
        trainer = trainer_raw.split("ï¼ˆ")[0].strip() if trainer_raw else "ä¸æ˜"

        jockey = _extract_jockey_from_cell(jockey_td)

        prev_jockey = ""
        if zenso_td:
            zenso_txt = zenso_td.get_text(" ", strip=True)
            m = _PREV_JOCKEY_RE.search(zenso_txt)
            if m:
                prev_jockey = m.group(1).strip().replace(" ", "")

        cj = _norm_name(jockey)
        pj = _norm_name(prev_jockey)
        is_change = bool(pj and cj and pj != cj)

        horses[str(umaban)] = {
            "waku": str(waku),
            "umaban": str(umaban),
            "horse": horse,
            "trainer": trainer if trainer else "ä¸æ˜",
            "jockey": jockey if jockey else "ä¸æ˜",
            "prev_jockey": prev_jockey,
            "is_change": is_change,
        }

    return header, horses, url

# ==================================================
# Difyï¼šå …ç‰¢ç‰ˆï¼ˆstreaming + blockingãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# ==================================================
def _dify_url(path: str) -> str:
    base = (DIFY_BASE_URL or "").strip().rstrip("/")
    return f"{base}{path}"

def _format_http_error(res: requests.Response) -> str:
    try:
        j = res.json()
        return f"âš ï¸ Dify HTTP {res.status_code}: {j}"
    except:
        txt = (res.text or "")[:800]
        return f"âš ï¸ Dify HTTP {res.status_code}: {txt}"

def stream_dify_workflow(full_text: str):
    """
    1) ã¾ãš streaming ã§å–ã‚Šã«è¡Œã
    2) HTTPã‚¨ãƒ©ãƒ¼ã¯å¿…ãšyieldã—ã¦çµ‚äº†ï¼ˆç„¡åå¿œåŒ–ã—ãªã„ï¼‰
    3) SSEå–ã‚Šã“ã¼ã—ã‚’é˜²ãï¼ˆdata:{}/data: {} ä¸¡å¯¾å¿œï¼‰
    4) workflow_finished/node_finished ã‹ã‚‰ outputs ã‚’å›å
    """
    if not DIFY_API_KEY:
        yield "âš ï¸ DIFY_API_KEYæœªè¨­å®š"
        return

    url = _dify_url("/v1/workflows/run")
    payload = {
        "inputs": {"text": full_text},
        "response_mode": "streaming",
        "user": "keiba-bot",
    }
    headers = {
        "Authorization": f"Bearer {DIFY_API_KEY}",
        "Content-Type": "application/json",
        "Accept": "text/event-stream",
        "Cache-Control": "no-cache",
    }

    sess = get_http_session()

    try:
        res = sess.post(url, headers=headers, json=payload, stream=True, timeout=300)

        # â˜…é‡è¦ï¼šHTTPã‚¨ãƒ©ãƒ¼ã‚’ã“ã“ã§æ½°ã™ï¼ˆç„¡åå¿œã®æœ€å¤§åŸå› ï¼‰
        if res.status_code != 200:
            yield _format_http_error(res)
            return

        got_any = False

        for line in res.iter_lines(decode_unicode=True):
            if not line:
                continue

            if not line.startswith("data:"):
                continue

            raw = line[5:].lstrip()  # "data:" ã®å¾Œã‚ï¼ˆç©ºç™½ã‚ã‚Š/ãªã—ä¸¡å¯¾å¿œï¼‰
            if not raw:
                continue

            try:
                evt = json.loads(raw)
            except:
                continue

            got_any = True

            # é€”ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸/ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆæ¥ã‚‹å ´åˆï¼‰
            if "answer" in evt and isinstance(evt["answer"], str) and evt["answer"]:
                yield evt["answer"]
                continue

            ev = evt.get("event")

            # node_finished ã® outputs ã‚’æ‹¾ã†ï¼ˆãƒ•ãƒ­ãƒ¼æ§‹æˆã«ã‚ˆã£ã¦ã¯ã“ã“ãŒä¸»ï¼‰
            if ev == "node_finished":
                data = evt.get("data", {}) or {}
                outputs = data.get("outputs", {}) or {}
                texts = [v for v in outputs.values() if isinstance(v, str) and v.strip()]
                if texts:
                    yield "".join(texts)
                continue

            # æœ€çµ‚
            if ev == "workflow_finished":
                data = evt.get("data", {}) or {}
                outputs = data.get("outputs", {}) or {}
                texts = [v for v in outputs.values() if isinstance(v, str) and v.strip()]
                if texts:
                    yield "".join(texts)
                else:
                    err = data.get("error")
                    status = data.get("status")
                    if err:
                        yield f"âš ï¸ workflow_finished error: {err}"
                    else:
                        yield f"âš ï¸ workflow_finished (status={status}) outputsãŒç©ºã§ã—ãŸ"
                return

        if not got_any:
            yield "âš ï¸ DifyãŒSSEã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸï¼ˆURL/ã‚­ãƒ¼/ã‚¢ãƒ—ãƒªç¨®åˆ¥/inputså/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¯èƒ½æ€§ï¼‰"

    except Exception as e:
        yield f"âš ï¸ Dify API Error: {str(e)}"

def run_dify_workflow_blocking(full_text: str) -> str:
    """streamingãŒãƒ€ãƒ¡ãªæ™‚ã®æœ€çµ‚æ‰‹æ®µï¼ˆçµæœã ã‘æ¬²ã—ã„ãªã‚‰ã“ã‚ŒãŒä¸€ç•ªå®‰å®šï¼‰"""
    if not DIFY_API_KEY:
        return "âš ï¸ DIFY_API_KEYæœªè¨­å®š"

    url = _dify_url("/v1/workflows/run")
    payload = {
        "inputs": {"text": full_text},
        "response_mode": "blocking",
        "user": "keiba-bot",
    }
    headers = {
        "Authorization": f"Bearer {DIFY_API_KEY}",
        "Content-Type": "application/json",
    }

    sess = get_http_session()

    try:
        res = sess.post(url, headers=headers, json=payload, timeout=300)
        if res.status_code != 200:
            return _format_http_error(res)

        j = res.json() or {}
        data = j.get("data", {}) or {}
        outputs = data.get("outputs", {}) or {}

        texts = [v for v in outputs.values() if isinstance(v, str) and v.strip()]
        if texts:
            return "".join(texts)

        err = data.get("error")
        if err:
            return f"âš ï¸ blocking error: {err}"

        return "âš ï¸ blockingã§ outputs ãŒç©ºã§ã—ãŸ"

    except Exception as e:
        return f"âš ï¸ blocking API Error: {str(e)}"

def run_dify_with_fallback(full_text: str) -> str:
    """
    streaming ã§å›å â†’ ä½•ã‚‚å¾—ã‚‰ã‚Œãªã„/ã‚¨ãƒ©ãƒ¼ã£ã½ã„æ™‚ã¯ blocking ã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    chunks = []
    for c in stream_dify_workflow(full_text):
        chunks.append(c)
        # streamingã‚¨ãƒ©ãƒ¼æ–‡ãŒæ¥ãŸã‚‰å³çµ‚äº†â†’blockingã¸
        if isinstance(c, str) and c.startswith("âš ï¸ Dify HTTP"):
            break
        if isinstance(c, str) and c.startswith("âš ï¸ Dify API Error"):
            break

    streamed = "".join(chunks).strip()

    # streamed ãŒç©ºã€ã‚‚ã—ãã¯ã€ŒSSEè¿”ã‚‰ãªã„ã€ç³»ã ã£ãŸã‚‰ blocking ã¸
    if (not streamed) or ("SSEã‚’è¿”ã—ã¾ã›ã‚“" in streamed) or (streamed.startswith("âš ï¸ Dify HTTP")):
        return (run_dify_workflow_blocking(full_text) or "").strip() or "âš ï¸ Difyå‡ºåŠ›ãŒç©ºã§ã—ãŸ"

    return streamed

# ==================================================
# ãƒ¡ã‚¤ãƒ³ï¼šå…¨ãƒ¬ãƒ¼ã‚¹å®Ÿè¡Œï¼ˆæ–‡å­—åˆ—ã‚’ returnï¼‰
# ==================================================
def run_all_races(
    year: str,
    month: str,
    day: str,
    place_code: str,
    target_races: set[int] | None,
    ui: bool = False,
) -> str:
    """
    place_codeï¼šç«¶é¦¬ãƒ–ãƒƒã‚¯å´ï¼ˆ10å¤§äº•/11å·å´/12èˆ¹æ©‹/13æµ¦å’Œï¼‰
    keiba.go.jp ã® babaCode ã¯å†…éƒ¨ã§ãƒãƒƒãƒ—

    ui=False: ç”»é¢æç”»ã›ãšçµæœæ–‡å­—åˆ—ã ã‘è¿”ã™
    ui=True : é€²æ—ã‚’ st.* ã§è¡¨ç¤º
    """
    place_names = {"10": "å¤§äº•", "11": "å·å´", "12": "èˆ¹æ©‹", "13": "æµ¦å’Œ"}
    place_name = place_names.get(place_code, "åœ°æ–¹")

    baba_map = {"10": "20", "11": "21", "12": "19", "13": "18"}
    baba_code = baba_map.get(place_code)
    if not baba_code:
        _ui_error(ui, "babaCode mapping ãŒæœªå®šç¾©ã§ã™ã€‚place_code ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return "âš ï¸ babaCode mapping ãŒæœªå®šç¾©ã§ã™ã€‚place_code ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

    result_blocks: list[str] = []

    driver = build_driver()
    wait = WebDriverWait(driver, 12)

    try:
        _ui_info(ui, "ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³ä¸­...ï¼ˆç«¶é¦¬ãƒ–ãƒƒã‚¯ï¼‰")
        login_keibabook(driver, wait)

        race_ids = fetch_race_ids_from_schedule(driver, year, month, day, place_code, ui=ui)
        if not race_ids:
            return "âš ï¸ ãƒ¬ãƒ¼ã‚¹IDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ—¥ä»˜/ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        for i, race_id in enumerate(race_ids):
            race_num = i + 1
            if target_races is not None and race_num not in target_races:
                continue

            race_num_str = f"{race_num:02}"

            _ui_markdown(ui, f"## {place_name} {race_num}R")
            _ui_caption(ui, f"race_id(keibabook): {race_id}")

            try:
                # 0) keiba.go.jp å‡ºé¦¬è¡¨
                header, keibago_dict, keibago_url = fetch_keibago_debatable_small(
                    year=str(year),
                    month=str(month),
                    day=str(day),
                    race_no=race_num,
                    baba_code=str(baba_code),
                )
                _ui_caption(ui, f"keiba.go.jp: {keibago_url}")
                if header:
                    _ui_caption(ui, f"keiba.go.jp header: {header}")

                if not keibago_dict:
                    _ui_warning(ui, "âš ï¸ keiba.go.jp ã‹ã‚‰å‡ºé¦¬è¡¨ãŒå–ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆç¶šè¡Œï¼šé¨æ‰‹/èª¿æ•™å¸«ãŒä¸æ˜ã«ãªã‚Šã¾ã™ï¼‰")

                # 1) è«‡è©±
                _ui_info(ui, "ğŸ“¡ ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...ï¼ˆè«‡è©±ï¼‰")
                driver.get(f"https://s.keibabook.co.jp/chihou/danwa/1/{race_id}")
                try:
                    wait.until(EC.presence_of_element_located((By.CLASS_NAME, "danwa")))
                except:
                    pass

                html_danwa = driver.page_source
                race_meta = parse_race_info(html_danwa)
                danwa_dict = parse_danwa_comments(html_danwa)

                # 2) èª¿æ•™
                _ui_info(ui, "ğŸ“¡ ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...ï¼ˆèª¿æ•™ï¼‰")
                driver.get(f"https://s.keibabook.co.jp/chihou/cyokyo/1/{race_id}")
                try:
                    wait.until(EC.presence_of_element_located((By.CLASS_NAME, "cyokyo")))
                except:
                    pass

                cyokyo_dict = parse_cyokyo(driver.page_source)

                # çµ±åˆï¼ˆé¦¬ç•ªã§æƒãˆã‚‹ï¼‰
                all_uma = sorted(
                    set(danwa_dict.keys()) | set(cyokyo_dict.keys()) | set(keibago_dict.keys()),
                    key=lambda x: int(x) if str(x).isdigit() else 999,
                )

                merged_text = []
                for uma in all_uma:
                    kg = keibago_dict.get(uma, {})
                    horse = kg.get("horse", "")
                    jockey = kg.get("jockey", "ä¸æ˜")
                    trainer = kg.get("trainer", "ä¸æ˜")
                    prev_jockey = kg.get("prev_jockey", "")
                    is_change = kg.get("is_change", False)

                    alert = "ã€âš ï¸ä¹—ã‚Šæ›¿ã‚ã‚Šã€‘" if is_change else ""
                    if prev_jockey:
                        alert += f"ï¼ˆå‰èµ°:{prev_jockey}ï¼‰"

                    d = danwa_dict.get(uma, "ï¼ˆãªã—ï¼‰")
                    c = cyokyo_dict.get(uma, "ï¼ˆãªã—ï¼‰")

                    merged_text.append(
                        f"â–¼[é¦¬ç•ª{uma}] é¦¬å:{horse} é¨æ‰‹:{jockey} {alert} èª¿æ•™å¸«:{trainer}\n"
                        f"è«‡è©±: {d}\n"
                        f"èª¿æ•™: {c}"
                    )

                if not merged_text:
                    block = f"ã€{place_name} {race_num}Rã€‘\nâš ï¸ ãƒ‡ãƒ¼ã‚¿ãªã—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—"
                    result_blocks.append(block)
                    _ui_warning(ui, "ãƒ‡ãƒ¼ã‚¿ãªã—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                    _ui_divider(ui)
                    continue

                prompt = (
                    f"{place_name}ç«¶é¦¬å ´ã®ãƒ¬ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚\n\n"
                    f"ãƒ¬ãƒ¼ã‚¹å: {race_meta.get('race_name','')}\n"
                    f"æ¡ä»¶: {race_meta.get('cond','')}\n\n"
                    "ä»¥ä¸‹ã®å„é¦¬ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆé¦¬åã€é¨æ‰‹ã€ä¹—ã‚Šæ›¿ã‚ã‚Šã€èª¿æ•™å¸«ã€è«‡è©±ã€èª¿æ•™ï¼‰ã§ã™ã€‚\n"
                    + "\n".join(merged_text)
                )

                # 3) Difyï¼ˆâ˜…ã“ã“ã‚’ â€œç¢ºå®Ÿã«â€ åå¿œã™ã‚‹å½¢ã«ï¼‰
                _ui_info(ui, "ğŸ¤– AIåˆ†æä¸­...ï¼ˆDifyï¼‰")
                full_ans = ""

                if ui:
                    # UIè¡¨ç¤ºã—ãªãŒã‚‰ï¼ˆstreamingï¼‰â†’ åå¿œãªã‘ã‚Œã°è‡ªå‹•ã§blockingã«åˆ‡ã‚Šæ›¿ãˆã‚‹
                    result_area = st.empty()

                    # ã¾ãš streaming ã‚’è©¦ã™ï¼ˆè¡¨ç¤ºã‚ã‚Šï¼‰
                    chunks = []
                    for chunk in stream_dify_workflow(prompt):
                        chunks.append(chunk)
                        tmp = "".join(chunks)
                        result_area.markdown(tmp + "â–Œ")

                        # æ˜ç¢ºãªHTTPã‚¨ãƒ©ãƒ¼ãªã‚‰æ­¢ã‚ã¦blockingã¸
                        if chunk.startswith("âš ï¸ Dify HTTP") or chunk.startswith("âš ï¸ Dify API Error"):
                            break

                    streamed = "".join(chunks).strip()

                    # ãƒ€ãƒ¡ãªã‚‰blockingã¸
                    if (not streamed) or ("SSEã‚’è¿”ã—ã¾ã›ã‚“" in streamed) or streamed.startswith("âš ï¸ Dify HTTP"):
                        streamed = run_dify_workflow_blocking(prompt)

                    full_ans = (streamed or "").strip()
                    result_area.markdown(full_ans if full_ans else "âš ï¸ AIã®å‡ºåŠ›ãŒç©ºã§ã—ãŸ")

                else:
                    # UIãªã—ï¼šæœ€åˆã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¾¼ã¿ã®å®‰å®šé–¢æ•°
                    full_ans = run_dify_with_fallback(prompt)

                full_ans = (full_ans or "").strip()
                if full_ans == "":
                    full_ans = "âš ï¸ AIã®å‡ºåŠ›ãŒç©ºã§ã—ãŸï¼ˆDifyå¿œç­”ãªã—/ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ï¼‰"

                _ui_success(ui, "âœ… å®Œäº†")

                save_history(year, place_code, place_name, month, day, race_num_str, race_id, full_ans)

                block = f"ã€{place_name} {race_num}Rã€‘\n{full_ans}"
                result_blocks.append(block)

            except Exception as e:
                msg = f"ã€{place_name} {race_num}Rã€‘\nâš ï¸ Error: {e}"
                result_blocks.append(msg)
                _ui_error(ui, f"Error: {e}")

            _ui_divider(ui)

    finally:
        try:
            driver.quit()
        except:
            pass

    return "\n\n".join(result_blocks).strip()

def run_races_iter(
    year: str,
    month: str,
    day: str,
    place_code: str,
    target_races: set[int] | None,
    ui: bool = False,
):
    """
    1ãƒ¬ãƒ¼ã‚¹å‡¦ç†ãŒå®Œäº†ã™ã‚‹ãŸã³ã« (race_num:int, block_text:str) ã‚’ yield
    app.py å´ã§é€æ¬¡è¡¨ç¤ºã™ã‚‹ç”¨é€”
    """
    place_names = {"10": "å¤§äº•", "11": "å·å´", "12": "èˆ¹æ©‹", "13": "æµ¦å’Œ"}
    place_name = place_names.get(place_code, "åœ°æ–¹")

    baba_map = {"10": "20", "11": "21", "12": "19", "13": "18"}
    baba_code = baba_map.get(place_code)
    if not baba_code:
        yield (0, "âš ï¸ babaCode mapping ãŒæœªå®šç¾©ã§ã™ã€‚place_code ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    driver = build_driver()
    wait = WebDriverWait(driver, 12)

    try:
        _ui_info(ui, "ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³ä¸­...ï¼ˆç«¶é¦¬ãƒ–ãƒƒã‚¯ï¼‰")
        login_keibabook(driver, wait)

        race_ids = fetch_race_ids_from_schedule(driver, year, month, day, place_code, ui=ui)
        if not race_ids:
            yield (0, "âš ï¸ ãƒ¬ãƒ¼ã‚¹IDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ—¥ä»˜/ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return

        for i, race_id in enumerate(race_ids):
            race_num = i + 1
            if target_races is not None and race_num not in target_races:
                continue

            race_num_str = f"{race_num:02}"

            _ui_markdown(ui, f"## {place_name} {race_num}R")
            _ui_caption(ui, f"race_id(keibabook): {race_id}")

            try:
                header, keibago_dict, keibago_url = fetch_keibago_debatable_small(
                    year=str(year),
                    month=str(month),
                    day=str(day),
                    race_no=race_num,
                    baba_code=str(baba_code),
                )
                _ui_caption(ui, f"keiba.go.jp: {keibago_url}")
                if header:
                    _ui_caption(ui, f"keiba.go.jp header: {header}")

                if not keibago_dict:
                    _ui_warning(ui, "âš ï¸ keiba.go.jp ã‹ã‚‰å‡ºé¦¬è¡¨ãŒå–ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆç¶šè¡Œï¼šé¨æ‰‹/èª¿æ•™å¸«ãŒä¸æ˜ã«ãªã‚Šã¾ã™ï¼‰")

                _ui_info(ui, "ğŸ“¡ ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...ï¼ˆè«‡è©±ï¼‰")
                driver.get(f"https://s.keibabook.co.jp/chihou/danwa/1/{race_id}")
                try:
                    wait.until(EC.presence_of_element_located((By.CLASS_NAME, "danwa")))
                except:
                    pass

                html_danwa = driver.page_source
                race_meta = parse_race_info(html_danwa)
                danwa_dict = parse_danwa_comments(html_danwa)

                _ui_info(ui, "ğŸ“¡ ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...ï¼ˆèª¿æ•™ï¼‰")
                driver.get(f"https://s.keibabook.co.jp/chihou/cyokyo/1/{race_id}")
                try:
                    wait.until(EC.presence_of_element_located((By.CLASS_NAME, "cyokyo")))
                except:
                    pass

                cyokyo_dict = parse_cyokyo(driver.page_source)

                all_uma = sorted(
                    set(danwa_dict.keys()) | set(cyokyo_dict.keys()) | set(keibago_dict.keys()),
                    key=lambda x: int(x) if str(x).isdigit() else 999,
                )

                merged_text = []
                for uma in all_uma:
                    kg = keibago_dict.get(uma, {})
                    horse = kg.get("horse", "")
                    jockey = kg.get("jockey", "ä¸æ˜")
                    trainer = kg.get("trainer", "ä¸æ˜")
                    prev_jockey = kg.get("prev_jockey", "")
                    is_change = kg.get("is_change", False)

                    alert = "ã€âš ï¸ä¹—ã‚Šæ›¿ã‚ã‚Šã€‘" if is_change else ""
                    if prev_jockey:
                        alert += f"ï¼ˆå‰èµ°:{prev_jockey}ï¼‰"

                    d = danwa_dict.get(uma, "ï¼ˆãªã—ï¼‰")
                    c = cyokyo_dict.get(uma, "ï¼ˆãªã—ï¼‰")

                    merged_text.append(
                        f"â–¼[é¦¬ç•ª{uma}] é¦¬å:{horse} é¨æ‰‹:{jockey} {alert} èª¿æ•™å¸«:{trainer}\n"
                        f"è«‡è©±: {d}\n"
                        f"èª¿æ•™: {c}"
                    )

                if not merged_text:
                    block = f"ã€{place_name} {race_num}Rã€‘\nâš ï¸ ãƒ‡ãƒ¼ã‚¿ãªã—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—"
                    yield (race_num, block)
                    _ui_warning(ui, "ãƒ‡ãƒ¼ã‚¿ãªã—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                    _ui_divider(ui)
                    continue

                prompt = (
                    f"ãƒ¬ãƒ¼ã‚¹å: {race_meta.get('race_name','')}\n"
                    f"æ¡ä»¶: {race_meta.get('cond','')}\n\n"
                    "ä»¥ä¸‹ã®å„é¦¬ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆé¦¬åã€é¨æ‰‹ã€ä¹—ã‚Šæ›¿ã‚ã‚Šã€èª¿æ•™å¸«ã€è«‡è©±ã€èª¿æ•™ï¼‰ã§ã™ã€‚\n"
                    + "\n".join(merged_text)
                )

                _ui_info(ui, "ğŸ¤– AIåˆ†æä¸­...ï¼ˆDifyï¼‰")
                full_ans = run_dify_with_fallback(prompt)

                full_ans = (full_ans or "").strip()
                if full_ans == "":
                    full_ans = "âš ï¸ AIã®å‡ºåŠ›ãŒç©ºã§ã—ãŸï¼ˆDifyå¿œç­”ãªã—/ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ï¼‰"

                _ui_success(ui, "âœ… å®Œäº†")

                save_history(year, place_code, place_name, month, day, race_num_str, race_id, full_ans)

                block = f"ã€{place_name} {race_num}Rã€‘\n{full_ans}"
                yield (race_num, block)

            except Exception as e:
                block = f"ã€{place_name} {race_num}Rã€‘\nâš ï¸ Error: {e}"
                yield (race_num, block)
                _ui_error(ui, f"Error: {e}")

            _ui_divider(ui)

    finally:
        try:
            driver.quit()
        except:
            pass
